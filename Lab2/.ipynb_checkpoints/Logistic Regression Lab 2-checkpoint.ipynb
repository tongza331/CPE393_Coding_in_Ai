{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Load  data\n",
    "\n",
    "Import \"bank-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bankData = pd.read_csv('bank-data.csv', sep = ';')\n",
    "bankData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Preprocess data\n",
    "\n",
    "Preprocess the dataset as you have done before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Binary encoding\n",
    "\n",
    "Use LabelEncoder to encode the following columns:\n",
    "- y\n",
    "- default\n",
    "- housing\n",
    "- loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "#example\n",
    "bankData['y'] = le.fit_transform(bankData['y'])\n",
    "bankData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the remaining columns\n",
    "bankData['housing'] = le.fit_transform(bankData['housing'])\n",
    "bankData['default'] = le.fit_transform(bankData['default'])\n",
    "bankData['loan'] = le.fit_transform(bankData['loan'])\n",
    "bankData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Convert categorical variables into dummy columns\n",
    "\n",
    "(1) Use pd.get_dummies to convert the following categorical variales into dummy columns\n",
    "- job\n",
    "- maritial\n",
    "- education\n",
    "- contact\n",
    "- month\n",
    "- poutcome\n",
    "\n",
    "(2) Drop columns that have been converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['job'],prefix='job')],axis=1)\n",
    "bankData = bankData.drop(columns=['job'])\n",
    "bankData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['marital'],prefix='marital')],axis=1)\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['education'],prefix='education')],axis=1)\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['contact'],prefix='contact')],axis=1)\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['month'],prefix='month')],axis=1)\n",
    "bankData = pd.concat([bankData,pd.get_dummies(bankData['poutcome'],prefix='poutcome')],axis=1)\n",
    "\n",
    "bankData = bankData.drop(columns=['marital', 'education', 'contact', 'month', 'poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Train/Test separation\n",
    "\n",
    "Perform hold-out method\n",
    "- 60% training set\n",
    "- 40% testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankData_train = bankData.sample(frac = 0.6)\n",
    "bankData_test = bankData.drop(bankData_train.index)\n",
    "print(pd.crosstab(bankData_train['y'],columns = 'count'))\n",
    "print(pd.crosstab(bankData_test['y'],columns = 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X/y separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankData_train_y = bankData_train['y']\n",
    "bankData_train_X = bankData_train.copy()\n",
    "del bankData_train_X['y']\n",
    "\n",
    "bankData_test_y = bankData_test['y']\n",
    "bankData_test_X = bankData_test.copy()\n",
    "del bankData_test_X['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Feature Scaling\n",
    "\n",
    "It is always a good practice to scale the features so that all of them can be uniformly evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "standard_scaler = preprocessing.StandardScaler()\n",
    "train_X_scaled_s = pd.DataFrame(standard_scaler.fit_transform(bankData_train_X), columns=bankData_train_X.columns)\n",
    "test_X_scaled_s = pd.DataFrame(standard_scaler.fit_transform(bankData_test_X), columns=bankData_train_X.columns)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "train_X_scaled_m = pd.DataFrame(min_max_scaler.fit_transform(bankData_train_X),columns=bankData_train_X.columns)\n",
    "test_X_scaled_m = pd.DataFrame(min_max_scaler.fit_transform(bankData_test_X),columns=bankData_train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_scaled_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_scaled_m.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Train a logistic regression model & Part 4: Model Evaluation\n",
    "\n",
    "Evaluation metrics\n",
    "- confusion metrix\n",
    "- accuracy\n",
    "- precision, recall, f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "lr.fit(bankData_train_X, bankData_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_importance = abs(lr.coef_[0])\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "\n",
    "\n",
    "lr_feature = pd.DataFrame({'feature':bankData_train_X.columns,\n",
    "                             'Score':feature_importance})\n",
    "\n",
    "lr_feature.sort_values(by = 'Score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = lr.predict(bankData_test_X)\n",
    "pd.crosstab(bankData_test_y, res)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\\t %.3f\" %accuracy_score(bankData_test_y, res))\n",
    "print(classification_report(bankData_test_y, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_s = linear_model.LogisticRegression()\n",
    "lr_s.fit(train_X_scaled_s, bankData_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_s.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_s = abs(lr_s.coef_[0])\n",
    "feature_importance_s = 100.0 * (feature_importance_s / feature_importance_s.max())\n",
    "\n",
    "\n",
    "lr_feature_s = pd.DataFrame({'feature':train_X_scaled_s.columns,\n",
    "                             'Score':feature_importance_s})\n",
    "\n",
    "lr_feature_s.sort_values(by = 'Score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_s = lr_s.predict(test_X_scaled_s)\n",
    "pd.crosstab(bankData_test_y, res_s)\n",
    "\n",
    "print(\"Accuracy:\\t %.3f\" %accuracy_score(bankData_test_y, res_s))\n",
    "print(classification_report(bankData_test_y, res_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_m = linear_model.LogisticRegression()\n",
    "lr_m.fit(train_X_scaled_m, bankData_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_m.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_m = abs(lr_m.coef_[0])\n",
    "feature_importance_m = 100.0 * (feature_importance_m / feature_importance_m.max())\n",
    "\n",
    "\n",
    "lr_feature_m = pd.DataFrame({'feature':train_X_scaled_m.columns,\n",
    "                             'Score':feature_importance_m})\n",
    "\n",
    "lr_feature_m.sort_values(by = 'Score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_m = lr_m.predict(test_X_scaled_m)\n",
    "pd.crosstab(bankData_test_y, res_m)\n",
    "\n",
    "print(\"Accuracy:\\t %.3f\" %accuracy_score(bankData_test_y, res_m))\n",
    "print(classification_report(bankData_test_y, res_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Model tuning\n",
    "\n",
    "#### Note:\n",
    "\n",
    "After building the classifier, try answering the following questions.\n",
    "\n",
    "1. What is the Accuracy Score?\n",
    "2. If you change your preprosessing method, can you improve the model?\n",
    "3. If you change your parameters setting, can you improve the model?\n",
    "\n",
    "You can look at the parameters and functions of Logistic Regression at http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
