{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jomGrnTqvzY2"
   },
   "source": [
    "# Lab 8: Training Deep Recurrent Neural Network - Part 2\n",
    "\n",
    "Name1, Student's ID1<br>\n",
    "\n",
    "## Lab Instruction - Language Modelling and Text Classification\n",
    "\n",
    "In this lab, you will learn to train a deep recurrent neural network using LSTM with the Keras library using the Tensorflow backend. Your task is to implement the natural language modelling and text generation.\n",
    "\n",
    "```\n",
    "alice_in_wonderland.txt\n",
    "```\n",
    "\n",
    "In class will use alice_in_wonderland as a text file. Then, you will train your language model using RNN-LSTM. \n",
    "\n",
    "\n",
    "\n",
    "- Language model (in Thai): http://bit.ly/language_model_1\n",
    "- Tutorial on how to create a language model (in English): https://medium.com/@shivambansal36/language-modelling-text-generation-using-lstms-deep-learning-for-nlp-ed36b224b275\n",
    "\n",
    "To evaluate the model, the perplexity measurement is used: https://stats.stackexchange.com/questions/10302/what-is-perplexity\n",
    "\n",
    "Last, fine-tune your model. You have to try different hyperparameter or adding more data. Discuss your result.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwoJBrLKvzY6"
   },
   "source": [
    "#### 1. Load your data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bcWCFsnfvzY7"
   },
   "outputs": [],
   "source": [
    "# Import require library\n",
    "from keras import *\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import _utils as fn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MLrjxZrNvzZA"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "import csv\n",
    "\n",
    "# Load data\n",
    "file = open(\"./alice_in_wonderland.txt\",\"r\",encoding=\"utf8\", errors='ignore')\n",
    "raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "StYO4DI-vzZE",
    "outputId": "be1ba59b-0f25-4d00-dd6d-a0e275cdeeb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER I.\\nDown the Rabbit-Hole\\n\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister was rea'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "X-9U1szlRb1q"
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuaAvGjnRkE7",
    "outputId": "ca6207ae-966c-4400-a149-f9008162513c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters:  82\n",
      "Total word:  29371\n"
     ]
    }
   ],
   "source": [
    "print(\"Total characters: \", len(chars))\n",
    "print(\"Total word: \", len(raw_text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qksGjaIJvzZJ"
   },
   "source": [
    "#### 2. Data Preprocessing \n",
    "\n",
    "*Note that only story will be used as a dataset, footnote and creddit are not include.*\n",
    "\n",
    "The symbol '\\n' is indicated the end of the line ``<EOS>``, which is for our model to end the sentence here.\n",
    "\n",
    "To create a corpus for your model. The following code is can be used:</br>\n",
    "*Note that other techniques can be used*\n",
    "\n",
    "```python\n",
    "# cut the text in semi-redundant sequences of maxlen characters.\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "```\n",
    "\n",
    "The code loop through the data from first word to the last word. The maxlen define a next n word for a model to predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Vj-YPtYsvzZK"
   },
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "GkIyzqV0RyJy",
    "outputId": "9d26846b-bded-4acf-86b0-d65176a61536"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER I.\\nDown the Rabbit-Hole <EOS> \\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister wa'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding end of string symbol use .replace   to replace data_text with  [  \\n\\n', \" <EOS> \" ]\n",
    "raw_text = raw_text.replace('\\n\\n', \" <EOS> \")\n",
    "raw_text[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AKE389h4vzZO"
   },
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "# Create corpus & Vectorization\n",
    "\n",
    "#Preprocessing \n",
    "# Create corpus & Vectorization\n",
    "\n",
    "tokenizer = text.Tokenizer()\n",
    "\n",
    "# basic cleanup\n",
    "corpus = raw_text.lower().split(\"\\n\")\n",
    "\n",
    "# tokenization\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "# Pre padding \n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "# One-hot label\n",
    "label = keras.utils.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07zFy2jotl1F",
    "outputId": "36a23194-881d-42f6-82ae-90e6f4dc7ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence len: 112\n",
      "Total word len: 3162\n"
     ]
    }
   ],
   "source": [
    "print('Max sequence len: %s' % max_sequence_len)\n",
    "print('Total word len: %s' % total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpPDrYsNtgX8",
    "outputId": "48d56216-fe6c-422c-c7f1-8fc29042da33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3160"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50nrDM_gtje1",
    "outputId": "99669d54-fc69-405b-9dab-06b22fb33bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0 330]\n"
     ]
    }
   ],
   "source": [
    "print(predictors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZzUBdMctjgx",
    "outputId": "f27d8da5-d125-4738-f26d-b95080ea9af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-ry6hn0vzZc"
   },
   "source": [
    "#### 3. Language Model\n",
    "\n",
    "Define RNN model using LSTM and word embedding representation</br>\n",
    "We will used perplexity as a metrics\n",
    "\n",
    "```python\n",
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = keras.backend.categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = keras.backend.pow(2.0, cross_entropy)\n",
    "    return perplexity\n",
    "```\n",
    "\n",
    "To used custom metrics function > https://keras.io/metrics/\n",
    "\n",
    "For a loss function `categorical_crossentropy` is used, any optimzation method can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "upTYjfZNvzZc"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding \n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout \n",
    "from keras.layers import Dense\n",
    "import keras.backend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xDOBkmNYvzZf"
   },
   "outputs": [],
   "source": [
    "def perplexity(y_true, y_pred):\n",
    "    cross_entropy = keras.backend.categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = keras.backend.pow(2.0, cross_entropy)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BFD82lMTTfQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAgBOsbrvzZj",
    "outputId": "8de1c916-2b09-4c33-8acd-7b3aca2049c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Embedding (Embedding)       (None, 111, 512)          1618944   \n",
      "                                                                 \n",
      " LSTM1 (LSTM)                (None, 111, 512)          2099200   \n",
      "                                                                 \n",
      " LSTM2 (LSTM)                (None, 256)               787456    \n",
      "                                                                 \n",
      " Output (Dense)              (None, 3162)              812634    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,318,234\n",
      "Trainable params: 5,318,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define your model\n",
    "# Used Word Embedding \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(total_words, 512,input_length=max_sequence_len-1,name='Embedding'))\n",
    "model.add(layers.LSTM(512, kernel_initializer = 'he_normal',\n",
    "                      dropout=0.3,\n",
    "                      return_sequences=True,\n",
    "                     name='LSTM1'))\n",
    "model.add(layers.LSTM(256, kernel_initializer = 'he_normal',\n",
    "                     dropout=0.3,\n",
    "                     name='LSTM2'))\n",
    "model.add(layers.Dense(total_words, activation='softmax',name='Output'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=[perplexity])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "65pM7pqNvzZm"
   },
   "outputs": [],
   "source": [
    "# Define your model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=[perplexity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8SYfwTCvzZr",
    "outputId": "04ce3dfe-a9a5-4cb1-d3f9-e543e46dc887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "893/893 [==============================] - 79s 81ms/step - loss: 6.1597 - perplexity: 302.4077\n",
      "Epoch 2/10\n",
      "893/893 [==============================] - 69s 77ms/step - loss: 5.6833 - perplexity: 211.7996\n",
      "Epoch 3/10\n",
      "893/893 [==============================] - 70s 79ms/step - loss: 5.3549 - perplexity: 156.3570\n",
      "Epoch 4/10\n",
      "893/893 [==============================] - 69s 77ms/step - loss: 5.0788 - perplexity: 118.4771\n",
      "Epoch 5/10\n",
      "893/893 [==============================] - 68s 76ms/step - loss: 4.8367 - perplexity: 90.7455\n",
      "Epoch 6/10\n",
      "893/893 [==============================] - 64s 72ms/step - loss: 4.6180 - perplexity: 71.1244\n",
      "Epoch 7/10\n",
      "893/893 [==============================] - 72s 80ms/step - loss: 4.4008 - perplexity: 55.5864\n",
      "Epoch 8/10\n",
      "893/893 [==============================] - 68s 77ms/step - loss: 4.1848 - perplexity: 44.8545\n",
      "Epoch 9/10\n",
      "893/893 [==============================] - 70s 78ms/step - loss: 3.9690 - perplexity: 36.5507\n",
      "Epoch 10/10\n",
      "893/893 [==============================] - 68s 76ms/step - loss: 3.7553 - perplexity: 30.3669\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(predictors, label,batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uZwRT6RvzZu"
   },
   "source": [
    "#### 4. Evaluate your model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9g4DkVi3vzZv"
   },
   "outputs": [],
   "source": [
    "# Create a function to evaluate your model using perplexity measurment (You can try adding other measurements as well)\n",
    "def evaluate_result(features, label, model):\n",
    "    model.evaluate(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6-pIYam3ACT",
    "outputId": "602eddb0-e0bd-44dc-a287-7c2e840fb94d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 [==============================] - 28s 30ms/step - loss: 3.4071 - perplexity: 21.0765\n"
     ]
    }
   ],
   "source": [
    "evaluate_result(predictors, label, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCU3FZjsvzZy"
   },
   "source": [
    "#### 5. Text generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jAd1Kdl3vzZz"
   },
   "outputs": [],
   "source": [
    "def generate_text(seedtext, next_words, max_sequence_len, model):\n",
    "  for j in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seedtext])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    #predicted = model.predict_classes(token_list, verbose=0)\n",
    "    predict_x=model.predict(token_list) \n",
    "    predicted =np.argmax(predict_x,axis=1)\n",
    "\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "      if index == predicted:\n",
    "        output_word = word\n",
    "        break\n",
    "    seedtext +=\" \" + output_word\n",
    "  return seedtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yC3AVscmvzZ4",
    "outputId": "0018b55d-1574-4159-f033-8aaad2890d80"
   },
   "outputs": [],
   "source": [
    "# generate your sample text\n",
    "\n",
    "seed_text = input('Enter your start sentence:')\n",
    "#generate_text , Input , Num_next_word,Max_sequence,Model\n",
    "gen_text = generate_text(seed_text,10,max_sequence_len,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-ZblD2rvZFnF",
    "outputId": "45ca21e6-5dd9-4234-d947-b7e5285af5b4"
   },
   "outputs": [],
   "source": [
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BaOPVnw1ZFos"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLz1ABUgvzaI"
   },
   "source": [
    "### More on Natural language Processing and Language model\n",
    "1. https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e \n",
    "2. https://medium.com/phrasee/neural-text-generation-generating-text-using-conditional-language-models-a37b69c7cd4b\n",
    "3. http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "**Music generates by RNN**\n",
    "https://soundcloud.com/optometrist-prime/recurrence-music-written-by-a-recurrent-neural-network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SscOleVkXxiG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkhYcG9vXxjq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab8_In_class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
