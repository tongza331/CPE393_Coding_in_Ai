{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b3ddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.convolutional import  MaxPooling2D\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e95100ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras import backend as K\n",
    "\n",
    "# define a function to plot the result from training step\n",
    "def show_result(history): \n",
    "    \n",
    "    # Print the result from the last epoch\n",
    "    print('Last train accuracy: %s'%history.history['accuracy'][-1])\n",
    "    print('Last validation accuracy: %s'%history.history['val_accuracy'][-1])\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "    epochs = range(1, len(loss) + 1)   \n",
    "    \n",
    "    # Define a subplot \n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,4))\n",
    "    \n",
    "    # Plot loss\n",
    "    loss_plot = axs[0]\n",
    "    \n",
    "    loss_plot.plot(epochs, loss, 'c--', label='Training loss')\n",
    "    loss_plot.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    loss_plot.set_title('Training and validation loss')\n",
    "    loss_plot.set_xlabel('Epochs')\n",
    "    loss_plot.set_ylabel('Loss')\n",
    "    loss_plot.legend()\n",
    "    \n",
    "    # Plot accuracy\n",
    "    acc_plot = axs[1]\n",
    "    \n",
    "    acc_plot.plot(epochs, acc, 'c--', label='Training acc')\n",
    "    acc_plot.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    acc_plot.set_title('Training and validation accuracy')\n",
    "    acc_plot.set_xlabel('Epochs')\n",
    "    acc_plot.set_ylabel('Accuracy')\n",
    "    acc_plot.legend()\n",
    "    \n",
    "def predict_class(model, image_file):\n",
    "    test_image = image.load_img(image_file, target_size=(64,64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image /= 255.0\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    images = np.vstack([test_image])\n",
    "    predict = model.predict_generator(images).argmax(axis=1)\n",
    "    plt.imshow(test_image)\n",
    "    if predict == 0:\n",
    "            plt.xlabel('predict: cat')\n",
    "    elif predict == 1:\n",
    "        plt.xlabel('predict: dog')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf464402",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe4d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir =  './Cat_Dog_data2/train/'\n",
    "validation_dir =  './Cat_Dog_data2/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a377b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 64\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7220372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b63a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = len([name for name in os.listdir(train_dir) for name in os.listdir(train_dir+name)])\n",
    "nb_validation = len([name for name in os.listdir(validation_dir) for name in os.listdir(validation_dir+name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2795619f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "print(nb_train)\n",
    "print(nb_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c73e97",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing and data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c2ee6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_SIZE,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "705f88e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "{'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255.0,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8453087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 2 classes.\n",
      "{'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "validate_datagen = ImageDataGenerator(rescale = 1./255.0)\n",
    "\n",
    "validate_generator = validate_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(validate_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37da68df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "[0 1]\n",
      "[11250 11250]\n"
     ]
    }
   ],
   "source": [
    "print('Training set')\n",
    "filename, label_count = np.unique(train_generator.classes, return_counts=True)\n",
    "print(filename)\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b34c0517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator[0][0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541a1f3",
   "metadata": {},
   "source": [
    "### 3. Build model (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import vgg16\n",
    "vggmodel = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354da9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                           epochs=20,\n",
    "                           steps_per_epoch=nb_train,\n",
    "                           validation_data=validate_generator,\n",
    "                           validation_steps=nb_validation,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3633ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
